{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework02: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE05FRSBmGUa"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "Izhzj8ALmGUb",
        "outputId": "a7fb996e-1fc4-4be8-ffdf-831cab5d1d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0     65      0 --:--:-- --:--:-- --:--:--    65\n",
            "100   342  100   342    0     0    607      0 --:--:-- --:--:-- --:--:--   607\n",
            "100  119M  100  119M    0     0  47.7M      0  0:00:02  0:00:02 --:--:-- 92.5M\n",
            "Train_rev1.csv\n"
          ]
        }
      ],
      "source": [
        "# uncomment and run this cell, if you don't have data locally yet.\n",
        "\n",
        "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "vwN72gd4ycOA"
      },
      "outputs": [],
      "source": [
        "# run this cell if you have downloaded the dataset on the seminar\n",
        "# data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "outputs": [],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUWkpd7PycOQ",
        "outputId": "7edd2042-4634-41d4-898c-8253c289afd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "239768it [00:25, 9374.94it/s] \n"
          ]
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "Y6in2TVGmGUe",
        "outputId": "16e5c224-f1d1-4333-8ffb-12e06286cdb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "token_counts.most_common(1)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "fb36dc6d-95c1-4881-8fe8-41f15d7e736a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "0aa5e3fe-7be5-44c2-8299-9b04a08b6d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "adeb1b13-fe0e-4244-e6c5-3f30f7f79831"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "08d2457f-f5a0-4373-a359-f350cefcb164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "outputs": [],
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zeto20H4mGUh"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "EtM1EZ7JmGUi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "20LSha59mGUj"
      },
      "outputs": [],
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJiwY548mGUj"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "xpPW3-V9mGUj"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "LoSdEoa8mGUk"
      },
      "outputs": [],
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "8sMtJ0AVmGUk"
      },
      "outputs": [],
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "Mle-KtRkmGUk",
        "outputId": "478e9ca1-a2f0-4ff9-a044-33da9ed171a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': array([[19821, 23579, 21211,    32,  3384,   736,    63, 14817,   156,\n",
              "         18192, 18192,     1],\n",
              "        [10387,  9544, 18664, 12023, 26688, 11346,     1,     1,     1,\n",
              "             1,     1,     1],\n",
              "        [ 9177, 24093, 18670, 12466, 21485,    15, 13049, 15402, 18192,\n",
              "           774, 19797,  7338]], dtype=int32),\n",
              " 'FullDescription': array([[19821, 23579, 21211,    32,  3384,   736,    63, 14817,   156,\n",
              "         18192, 22495,    80,    80, 22152,   195, 14818,  5501, 25112,\n",
              "         14109,  3682,  3185, 30411,  7338, 30762, 29561,  1894, 13513,\n",
              "         21405, 14232, 28795, 30762, 30411, 19678, 21405,  8632, 12466,\n",
              "         18145,  2810,   167, 32718,  2545,  8091, 25110,   965, 23579,\n",
              "         21211, 30762, 24244,  7677, 30762,   965, 19615, 19230,  5722,\n",
              "         15402, 14817,   167, 30411, 21211, 33079, 33306,  2662, 22347,\n",
              "         21405,   965, 20208,  9284, 23865, 14232, 30080,  8713, 13153,\n",
              "         19230, 27463,  2166, 10407, 21405, 21347, 14229, 30762, 19615,\n",
              "         22810,   167, 30411, 29406,  5221, 33079,  3607, 25722, 30762,\n",
              "         33306, 31806, 15402, 24253, 21220,  2166, 23605, 14784, 10520,\n",
              "          5333, 30762, 30411, 19230,  5722, 23367,   167, 11068, 20357,\n",
              "          3607, 25355, 33198, 30411, 20887,  2166, 14632,   965, 32019,\n",
              "         23067,   167, 21573, 33585,    18, 26612, 26839, 23844, 11453,\n",
              "          2892,  3384,   736,   167, 19674, 21405, 21573, 30762, 31438,\n",
              "         33591, 23445, 25361, 11453, 15402, 23865, 14229,  5333, 23579,\n",
              "           167, 11458,  2166,  6880, 15402, 15313,   156, 32140,   156,\n",
              "          3022,   167, 22448, 13699,  9236,    32, 22903,    63, 15402,\n",
              "           965, 25440,  6813, 14229,  9285, 21784, 23386, 11231, 21405,\n",
              "         10958, 11453,   167, 15402, 25977, 32718,  5196, 21416, 22792,\n",
              "         22667, 23137,  8595, 30080, 30762, 13766, 33635, 30578, 33642,\n",
              "         25361, 12698, 18714, 31046, 32802, 22495,  3184, 21405,    80,\n",
              "         15187, 33635, 14109, 23844, 19615, 11453,   167, 30512, 23445,\n",
              "         16289, 29312, 30762, 23663,  2166, 25239,  5961,   167,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1],\n",
              "        [26324,   891, 10387,  9544, 18664, 12023, 26688, 11346, 18132,\n",
              "           891, 32530, 26682,   891,    80,  3523, 21945,    80, 23248,\n",
              "         11295,  3771, 15447,  5303,   195,  5303,  1937,   156, 19802,\n",
              "         22958,   156, 17432,   156, 21590, 15424,  2166, 24050, 27572,\n",
              "         26961, 25672, 30762, 30411, 13699, 26688, 18670,   156, 33635,\n",
              "         33079,  3607, 13168, 17580,  2166,  7071, 11645, 30762, 11645,\n",
              "          2421, 12466, 30411, 10218, 26688,  9474,   167, 25861, 13168,\n",
              "         17580,   156,  2420, 27485,  2166,  7071, 26688,  2421, 15447,\n",
              "         12518, 23780,  9108, 18664, 30762, 10778, 26688, 21715,  2545,\n",
              "         19027, 31830, 26688,  7865, 29822, 33198, 24079,  2166, 12924,\n",
              "         21715,  5134, 21556, 30411, 11390,  8114,  3508, 30762, 13165,\n",
              "          1390,  4938,  2972, 26688, 19267,  2166, 23785, 25916, 12466,\n",
              "         18664, 25672, 28011,  2166, 11453,  2892, 17622,   437, 33591,\n",
              "         21405, 11453, 15402,   965,  3238, 26688, 26324, 33209, 30411,\n",
              "         23886,  2166, 10387,  9544, 18664, 27463, 24240, 30985, 25078,\n",
              "         21405, 29402, 15402, 20697,  4938, 26688, 13446, 33438,  2166,\n",
              "         32158,  6806, 28011,  5196,  9526,  2985, 27283,  2166,   965,\n",
              "         13446, 30080, 23189,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1],\n",
              "        [ 9177, 24093, 18670, 33198, 32773,   195,  9177, 23876,    80,\n",
              "         24093, 18664, 11453, 12466,   965,   774, 19941,  7338, 33198,\n",
              "           965, 30625, 21573, 21485,  2166, 13049,  6835, 15402, 18192,\n",
              "         22504,    80, 22570,   167,   965, 30625, 21573, 21485,  2166,\n",
              "         13049,  6835, 14109,   965, 24093, 16187, 22048,    80, 32774,\n",
              "           167, 30411, 24093, 21290, 16289, 30762, 27175, 30411,  6831,\n",
              "         17576, 28928, 15402, 30411, 15563, 33209,  9177,  6806, 30578,\n",
              "           965, 27479, 21405, 15390, 30762, 30411, 23176,   167, 30411,\n",
              "         27345, 24093, 18670, 27960, 22048, 30512, 24093, 14083,   965,\n",
              "         17437, 33338,  2166, 25734,   965, 16837, 24093, 18670, 30762,\n",
              "         29894, 22048, 25861, 33209, 23148,   156, 19920,   156, 24093,\n",
              "          1461,   156, 17829, 33198, 17041, 28828,  2166, 25672,  3259,\n",
              "         30762, 30411, 27345, 23253,   167, 30411, 15142,  5221, 12466,\n",
              "         30512, 26324, 33079,  3607, 14632,   965, 24093, 18664,  5763,\n",
              "          2166, 11453, 21405, 33331, 33209, 17437, 13360, 21836, 21556,\n",
              "         17437, 26907,  9177, 24114,  2662,   965, 24093, 18670,   167,\n",
              "         30512, 16289,  2120, 15706,   774, 19941,  7338, 14860, 30411,\n",
              "          3151,  7343, 17714, 21556, 27943, 16289,  3864,   494, 33591,\n",
              "          2166, 16289, 31594,   167,  3512, 15402, 18192,  2166, 22504,\n",
              "         31823, 30762,    80, 22570,   167, 15187, 33635,  2545, 15972,\n",
              "         21784, 23148, 30762, 18606,   965,  5847, 23212, 29324, 33642,\n",
              "         31823, 30762,  8381,  8167, 30762,  3607, 26005,  5016, 21972,\n",
              "         25821, 30080, 33010, 33079,  5124, 33635, 27736, 30487, 11931,\n",
              "         30512, 26324, 16289,   965, 13446, 18961, 12466, 33642, 28004,\n",
              "         27479, 33198, 22048,   647, 33591, 21405, 28537, 11453,   156,\n",
              "          1532, 30131, 25833, 16289, 30411, 25107, 21405,  6076, 12466,\n",
              "         16378,  2166, 10705, 24027,  1297, 10514,   167, 33331, 33198,\n",
              "         28365, 21405, 30411, 17576, 10570,  2594, 30411, 33374,   156,\n",
              "          1532, 21421, 13360,  7338,  2166, 22759,  5337, 21715,  1297,\n",
              "           965, 33043, 24786, 21405, 15561,  2166, 27172,   167, 23212,\n",
              "         32335, 21972, 32773, 30762, 12119, 21977, 19981,  1057, 31909,\n",
              "           167,  1532, 30131, 25833,   891, 27463, 21417,  2545, 30537,\n",
              "         21405,  2120, 10572,  1675, 12466, 22759, 33306,  2166,   195,\n",
              "         21784, 10572,  4938, 12466, 30411, 29561, 21405,  7338,   195,\n",
              "         30268, 33306,   167, 30512, 16658, 32637, 21870, 23459,  2662,\n",
              "         33468,   167,  8199,   167,  6489,   167, 31523,   195, 16679,\n",
              "           195,     0,    80]], dtype=int32),\n",
              " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tEqdoIDmGUl"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "GyZ9gjftmGUl",
        "outputId": "bc624f53-7eb8-4af8-c006-13a4ab0e652b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1552],\n",
              "        [0.1824],\n",
              "        [0.0344]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ],
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "a8eTkuIQmGUl",
        "outputId": "e3626bbb-e72a-4a5e-e580-3c97a4d65590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 327)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "batch['FullDescription'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHBoOFDgmGUl"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "SBbK9daFmGUl"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import clear_output\n",
        "# from random import sample\n",
        "\n",
        "# epochs = 1\n",
        "\n",
        "# model = simple_model\n",
        "# opt = torch.optim.Adam(model.parameters())\n",
        "# loss_func = nn.MSELoss()\n",
        "\n",
        "# history = []\n",
        "# for epoch_num in range(epochs):\n",
        "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "#         # Preprocessing the batch data and target\n",
        "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "#         target = torch.tensor(target)\n",
        "\n",
        "\n",
        "#         predictions = model(batch)\n",
        "#         predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "#         # train with backprop\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         opt.zero_grad()\n",
        "#         # <YOUR CODE HERE>\n",
        "\n",
        "#         history.append(loss.data.numpy())\n",
        "#         if (idx+1)%10==0:\n",
        "#             clear_output(True)\n",
        "#             plt.plot(history,label='loss')\n",
        "#             plt.legend()\n",
        "#             plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MplIHX9UmGUm"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "xMk-1WzDmGUm"
      },
      "outputs": [],
      "source": [
        "import network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "i_nuVc51mGUm",
        "outputId": "466e9964-bbc6-4796-a7e0-29f429873754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ],
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "kivcpuHcmGUm"
      },
      "outputs": [],
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        "    concat_number_of_features = 192\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "vI_mfV4lmGUm"
      },
      "outputs": [],
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "uyzlnftrmGUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8b7ac8-6168-4a14-84fb-02ffe54ea65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boNuSUrpmGUn"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "dwPD-yMymGUn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "009f62d8-c58a-43d4-d484-4826d2e70fdf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Training pipeline comes here (almost the same as for the simple_model)\n",
        "from IPython.display import clear_output\n",
        "epochs = 1\n",
        "\n",
        "model = model\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch_title = torch.tensor(batch['Title'], dtype=torch.long)\n",
        "        batch_full = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "        batch_category = torch.tensor(batch['Categorical'])\n",
        "\n",
        "        target = torch.tensor(target)\n",
        "        whole_input = [batch_title, batch_full, batch_category]\n",
        "\n",
        "        predictions = model(whole_input)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)# \n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        # \n",
        "\n",
        "        history.append(loss.data.numpy())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5bswcO9mGUn"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "S43N9PTNmGUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a899db-772c-448b-db41-21aea4468321"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_emb): Embedding(33795, 64)\n",
              "  (title_conv_pooling): Sequential(\n",
              "    (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (full_emb): Embedding(33795, 64)\n",
              "  (full_conv_pooling): Sequential(\n",
              "    (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (category_out): Linear(in_features=3746, out_features=64, bias=True)\n",
              "  (batch): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (inter_dense): Linear(in_features=192, out_features=128, bias=True)\n",
              "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "HONIluBtmGUv"
      },
      "outputs": [],
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "k8xwRCGUmGUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121aead1-467c-4151-c3a4-abfc745b63ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:05,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.36960\n",
            "Mean absolute error: 0.47263\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joGJDY_fmGUv"
      },
      "source": [
        "__Both the notebook and the `.py` file are required to submit this homework.__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}